# Major components

1. [Run Manager](#Run-Manager)
2. [Data Manager](#Data-Manager)
3. [Notification Manager](#Notification-Manager)
4. [Visualization Manager](#Visualization-Manager)

<a name="Run-Manager"/>
## Run Manager
</a>
### Sub components

#### run list

A list of all the users previous runs. Each run is made up of:

1. reproducability provenance, all the information needed to re-do the run manually. Link to proven dashboard for all the detailed run provenance data.
2. the current status of the run (queued, running (elapsed time), completed, failed, error)
3. file output of the run, i.e. files generated by the run.
4. console output for the run.
5. meta-data about the run, who started the run, which tempalate it came from, when it started/stopped, what the elapsed time was.
6. share button to give others users the ability to see the run information.


#### run editor

An editor to create new runs. The editor will consist of:

1. A list of supported run types (amwg diagnostic, ncclimo, time series, acme diags, ect).
2. For each run type, a sub component allowing for configuration of the run
3. Each run consists of a list of jobs, a run isn't one instance of one job but can be a set of jobs that are executed in sequence.

#### run queue

A view of the global queue status. The run queue will show the user:

1. A global run queue showing the status of all jobs in the system.
2. Filter to show only my jobs
3. Each run will only show the run name, run id, and run status.

#### run templates

A list of all the run configurations the user has created in the past. This will allow them to create a run template that they can run multiple times with small changes. 

1. List of saved run templates.
2. A sharing option to give another user a copy of the template.
3. Each run template will consist of the name of the run, and a button to open it in the run editor.
4. Each run template will have a list of previous runs of this type.

<a name="Data-Manager"/>
## Data Manager
</a>
### Sub components

#### User data 

A display of all data currently available to the user. This is local data stored on the server that the user has access to. All user data is broken up into four catagories:

1. Model data, raw data produced by a model.
2. Diagnostic data, plots and netcdf data produced by diagnostics.
3. Observation data, data produced by remote sensing mechanisms.
4. Job output, data produced by running processing jobs, i.e. regridded climotologies,  or time series.
5. A list of all the users current data transfers.

#### Data type

Each of the four types of data will have a display. This will consist of:

1. A list of the data available to this user of this type, sorted into directories per dataset.
2. Each directory will have a list of all the files/sub directories, with the ability to filter by file name.
3. A search option for all data of the given type, i.e. search all my diagnostic data for plots with PRECT in the title.
4. An option to share a dataset with another user. If a dataset has been shared with me from another user, show who shared the data.
5. Each dataset should show its source (who shared the data, which remote server it was downloaded from, its ESGF source).
6. If the data was downloaded from ESGF, a view of all the ESGF metadata associated with the data.

#### Data import

Users will have the ability to import data from a variety of sources. The import view will give them the option to select one of the following:

1. Import from [ESGF](#Esgf-import)
2. Upload from users [machine](#Data-upload)
3. Download from [remote source](#Remote-download)

<a name="Esgf-import"/>
#### Esgf import
</a>
The user can import datasets directly from esgf.

1. The user can select a set of nodes to search. They will be prometed for their credentials and authenticated via the first node in the list.
2. The user can then select a set of search parameters for those nodes. This will consist of a list of facets and all the available options for that facet.
3. Once they have searched the node, they will be given a list of all the data that matches their query. This will show them all the metadata about the dataset, and an option to import the data into their personal store on the workbench server. This will start a esgf download, which will appear on the main data manager view. Once the download has started, it will display a button to move them back to the data manager root view, or continue browsing.

<a name="Data-upload"/>
#### Data upload
</a>
The user will have the ability to upload their own data to the server for analysis. This view will consist of:

1. A prompt to select the type of data their uploading (model, obs, diag, post-processing).
2. Once they have selected a data type, they will select the file path on their local machine.
3. Once they've selected the path, they can hit the "upload" button to start the transfer, or a "cancel" button to clear all the fields.
4. When the transfer has started, the user will be given a prompt to take them back to the data manager root, or create a new data upload.

<a name="Remote-download"/>
#### Remote download
</a>
The user will be able to select a remote server to retieve data from. This will only support http file transfers for public data from remote servers. This view will consist of:

1. A prompt to select the type of data.
2. A prompt to enter the remote url where the data can be found.
3. A prompt to create a name for the dataset.
4. Once they have entered all the required information, a button to start the transfer, or clear the fields.
5. Once the transfer has started, a prompt to take them back to the data manager root or continue adding remote download jobs.

<a name="Notification-Manager"/>
## Notification Manager
</a>
### Sub componenets

#### Notification list

This is simply a list of all notifications. The list will consist of:

1. A list of entries, where each entry is one notification.
2. A drop down menue for search filters, i.e. only show download jobs, only show runs of a given name

#### Notification item

This is the actual notification card for each event. Each job will create its own card, which will consist of:

1. Metadata about the job, the jobs name, when it started, elapsed time, ect
2. The current job status (queued, completed, failed, error)
3. A list of sub-events, the job was added to the queue, the job was started, the job finished.
4. If the job is complete, a button to open the job output.

<a name="Visualization-Manager"/>
## Visualization Manager
</a>
### Sub components

#### Data select

This will be the vis manager root, and give the user the ability to select what data they want to inspect. It will utilize the Data Managers [file view](#User-data). Once the user has selected their data file to visualize, they will be taken the to visualization view.

#### Visualization view

This is where the user will see their visualization. The visualizations will only use a set of predefined templates for ease of use. For more advanced users, they will be promped to open the data in the server version of vCDAT. The visualization flow will work as follows:

1. The user will be prompted to select a variable from the available variables in the data.
2. The user will select a template from the templates provided.
3. The plot will be generated by the server and displayed in the browser window. The user will have the option of saving the image or changing the parameters and regenerating. 
4. The save option will give them a list of options to save it, download the image to their local machine, save it to their diagnostics folder on the server, or email it to a given address.